[{"title":"MQ引入","url":"/2025/07/26/MQ%E5%BC%95%E5%85%A5/","content":"同步&#x2F;异步通讯首先，我们知道MQ（Message Queue，消息队列）是一种通信机制，那通讯机制又是什么呢？\n\n通讯机制又分为同步通讯和异步通讯\n同步通讯可以看作是用手机给别人打电话，双方的交互是实时的，这时可以立即得到响应，但是你却不能跟多个人同时通话。\n异步通讯就好比微信发送消息，双方的交互并不是实时的，你可以立即回复消息，也可以等一段时间回复，这样就会使得消息之间的传递有延迟，但是你还可以同时与多个人收发消息。\n\n\n\n所以，如果我们的业务需要实时得到服务提供方的响应，则应该选择同步通讯（同步调用），而如果我们追求更高的效率，并且不需要实时响应，则应该选择异步通讯（异步调用）。\n接下来我们再来理解一下同步调用和异步调用。\n同步调用以下根据一个支付服务对同步业务进行解析\n\n\n首先解释一下业务流程：\n\n支付服务需要先调用用户服务完成余额扣减\n然后支付服务自己要更新支付流水单的状态\n然后支付服务调用交易服务，更新业务订单状态为已支付\n\n三个步骤依次执行。\n看似没有问题，逻辑清晰，但是其中存在三个问题\n\n拓展性差\n\n如果在业务后期需要给它加入一个短信通知业务，积分业务等等。。\n\n\n每次添加业务都需要修改大量代码（不仅要在支付服务的接口中定义新的接口，新的接口又与旧的接口中有交互），非常臃肿，不符合开闭原则，拓展性不好。\n\n性能差\n\n调用者需要等待上一个服务执行完之后，有结果后，才能继续向下执行，也就是说每次调用，调用者都是处于阻塞等待状态。最终整个业务的响应时长就是每次调用的执行时长之和：\n\n\n假如每个微服务的执行时长都是50ms，则最终整个业务的耗时可能高达300ms，性能太差了，用户都等炸毛了。\n\n级联失败\n\n\n“级联失败”（Cascading Failure）是一个在分布式系统中常见的现象，指的是一个系统中的某个组件或服务发生故障时，导致其他相关联的组件或服务也相继发生故障，从而引发整个系统的崩溃或性能大幅下降。\n\n由于我们是基于OpenFeign调用交易服务、通知服务。当交易服务、通知服务出现故障时，整个事务都会回滚，交易失败。\n如果只是因为短信通知故障，导致之前收到的钱又返还了，是很得不偿失的，因为你不知道这个用户是否还会在你这里进行购物。。。。\n（OpenFeign 是一个用于简化 HTTP 请求的 Java 库，主要用于服务间的通信。它通过声明式的方式，使得开发者能够更简洁地发起 RESTful 请求，而不需要显式地编写底层的 HTTP 客户端代码。在这里不用过多了解）\n这其实就是同步调用的级联失败问题。\n针对于这三个问题，我们就必须用异步调用的方式来代替同步调用。\n异步调用异步调用方式其实就是基于消息通知的方式，一般包含三个角色：\n\n消息发送者：投递消息的人，就是原来的调用方（对应上面的例子就是支付服务）\n消息Broker：管理、暂存、转发消息，你可以把它理解成微信服务器。\n消息接收者：接收和处理消息的人，就是原来的服务提供方（对应上面的交易服务，通知服务等等。。）\n\n在异步调用中，发送者不再直接同步调用接收者的业务接口，而是发送一条消息投递给消息Broker。\n然后接收者根据自己的需求从消息Broker那里订阅消息。每当发送方发送消息后，接受者都能获取消息并处理。\n这样，发送消息的人和接收消息的人就完全解耦了。\n就好比送外卖，同步调用就是外卖小哥外卖送到了必须等你在他手上把外卖拿走了才能送下一旦，异步调用就是他送到了，直接把外卖放在外卖柜上（Broker），然后给你发个消息“外卖到了”，你也只用接收“外卖到了”这个消息就好。\n\n针对于刚刚的例子，只用在用户服务完成之后，返回支付服务发送一条消息，然后接下来的交易服务，通知服务，积分服务都只需要监听这个消息即可，他们之间是相互独立的，并发的。\n\n\n不管后期增加了多少消息订阅者，作为支付服务来讲，执行问扣减余额、更新支付流水状态后，发送消息即可，不再需要在代码中增加对其他新的业务的调用。业务耗时仅仅是这三部分业务耗时，仅仅100ms，大大提高了业务性能。\n另外，不管是交易服务、通知服务，还是积分服务，他们的业务与支付关联度低，现在采用了异步调用，解除了耦合，他们即便执行过程中出现了故障，也不会影响到支付服务，解决了级联失败。\n同时有业务功能的添加也不需要动源代码，只需接收他们发出的消息即可，拓展性更好。\n这样的话它的压力主要集中在发送消息这一步，后续的服务可以根据自己的能力按需处理消息，相对来说很平稳，这种现象我们可以理解为削峰。\n\n\n\nMQ综上来看，MQ的本质就是一个阻塞队列， 只不过它在阻塞队列的基础上增加了重试, 消息持久化等等功能.。\n那它有什么优缺点呢？\n我们用去咖啡店买咖啡为例，如果是采用同步通讯的方法去买咖啡，我们给咖啡馆店员点餐后，我们还需要站在柜台等待他把咖啡做完，然后下一位顾客才可以进行点单，整个一条队伍把咖啡都买完的时间非常久。\n\n异步\n\n如果我们在其中运用MQ的思维，在吧台准备一个自动点餐机，用户可以在上面自行点餐，然后生成一张小票，点完之后，用户就可以走了，不用等待店员把咖啡做好，而咖啡馆店员也不用在吧台等别人来点餐，他只需要在后台备料，等有订单了，再去着手做咖啡。这就是异步。\n\n解耦\n\n在点单过后，店员就着手于做咖啡，而顾客也不用站在队伍里等候，顾客可以去上厕所，可以去买早餐，这就达到了解耦的目的。\n\n削峰\n\n在人流量很大的时候，比如早高峰，很多人都需要购买咖啡，然后不同的店员做咖啡的效率不一样，每个顾客点的咖啡做的难度也不一样，店员谁有空谁就去做下一杯，就可以避免一个店员过载导致的等待时间过长，这就是削峰。\n虽然有很多优点，但是这种模式下也会有缺点。\n\n可用性降低\n\n系统不同服务之间就靠一个MQ连接，如果MQ挂了，整个服务器就崩溃了（虽然不太可能）。\n\n复杂度更高\n\n消息的重复出现，消息是否会失效，还有顺序问题都导致了系统复杂的更高。\n\n数据一致性的问题\n\n系统中难免会发生某一个业务出现问题，就比如B,C,D三个服务都需要对同一个事务进行数据库的写入或者修改，B,C都成功了，D失败了，整个事务在数据库中的状态就不一样了，这也是需要考虑的点。\n","categories":["MQ"],"tags":["MQ"]},{"title":"消息的可靠性","url":"/2025/07/27/%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7/","content":"消息丢失消息从发送者发送消息，到消费者处理消息，需要经过的流程是这样的：\n\n\n消息从生产者到消费者的每一步都可能导致消息丢失：\n\n发送消息时消息丢失\n生产者发送消息到交换机时\n交换机把消息发送给队列时\n\n\nMQ导致消息丢失\n消息没来得及发送给消费者就消失了\n\n\n消费者拿到消息后未消费导致消息丢失\n消费者拿到消息没来得及消费就消失了\n\n\n\n消息的可靠性综上，我们要解决消息丢失问题，保证MQ的可靠性，就必须从3个方面入手：\n\n确保生产者一定把消息发送到MQ\n确保MQ不会将消息弄丢\n确保消费者一定要处理消息\n\n生产者的可靠性生产者确认生产者在向交换机传输消息时，有可能消息根本无法到达交换机，或者到达交换机后没有成功的将消息传递给队列，所以MQ针对这两点分别做出了保障，我们称之为生产者的确认。\nConfirm模式：确保消息送达交换机当消息成功到达 RabbitMQ 的交换机（Exchange）时，RabbitMQ 就会返回 ack 投递失败返回nack。\n想要开启confirm模式也很简单，在publisher模块的application.yaml中添加配置：\nspring:  rabbitmq:    publisher-confirm-type: correlated # 开启publisher confirm机制，并设置confirm类型\n\n这里publisher-confirm-type有三种模式可选：\n\nnone：关闭confirm机制\nsimple：同步阻塞等待MQ的回执（等信息返回了再执行其他操作）\ncorrelated：MQ异步回调返回回执（发完消息直接做其他事情，有消息回调回来再进行处理）\n\nReturn回退机制：确保消息路由成功在消息到达Exchange过后，MQ会返回ack，但是这并不代表消息就可以成功发送给队列，因此还需要一层return机制来保证：确保消息成功从交换机路由到目标队列，未路由的消息能被回退感知。\n想要开启confirm模式也很简单，在publisher模块的application.yaml中添加配置：\nspring:  rabbitmq:    publisher-confirm-type: correlated  # 启用 confirm 机制    publisher-returns: true            # 启用 return 回调（还需 mandatory 才生效）    template:      mandatory: true                  # 配合 return 生效，消息未路由才触发回调，默认false会在失败后直接丢弃消息\n\n生产者确认机制的实现经过梳理整个生产者确认机制如下图：\n\n\n我们现在来实现一下：\n\n配置publisher模块的application.yaml\n\nspring:  rabbitmq:    publisher-confirm-type: correlated  # 启用 confirm 机制    publisher-returns: true            # 启用 return 回调（还需 mandatory 才生效）    template:      mandatory: true                  # 配合 return 生效，消息未路由才触发回调\n\n\n配置ConfirmCallback\n\n由于每个消息发送时的处理逻辑不一定相同，因此ConfirmCallback需要在每次发消息时定义。具体来说，是在调用RabbitTemplate中的convertAndSend方法时，多传递一个参数：\n\n\n这里的CorrelationData中包含两个核心的东西：\n\nid：消息的唯一标示，MQ对不同的消息的回执以此做判断，避免混淆\nSettableListenableFuture：回执结果的Future对象\n\n将来MQ的回执就会通过这个Future来返回，我们可以提前给CorrelationData中的Future添加回调函数来处理消息回执：\n\n\n\n配置ReturnCallback\n\n每个RabbitTemplate只能配置一个ReturnCallback，因此我们可以在配置类中统一设置，是一种初始化的操作，我们可以使用@PostConstruct来实现。\n（@PostConstruct 是 Java 中的一个注解，常用于标记方法，使其在对象实例化并完成依赖注入后立即执行。它通常用于初始化逻辑，例如加载配置、建立连接等。）\n我们建立一个MqReturnConfig配置类：\n@Slf4j@AllArgsConstructor@Configurationpublic class MqReturnConfig &#123;    private final RabbitTemplate rabbitTemplate;    @PostConstruct    public void init()&#123;        rabbitTemplate.setReturnsCallback(new RabbitTemplate.ReturnsCallback() &#123;            @Override            public void returnedMessage(ReturnedMessage returned) &#123;                log.debug(&quot;exchange: &#123;&#125;&quot;, returned.getExchange());                log.debug(&quot;routingKey: &#123;&#125;&quot;, returned.getRoutingKey());                log.debug(&quot;message: &#123;&#125;&quot;, returned.getMessage());                log.debug(&quot;replyCode: &#123;&#125;&quot;, returned.getReplyCode());                log.debug(&quot;replyText: &#123;&#125;&quot;, returned.getReplyText());            &#125;        &#125;);    &#125;&#125;\n\n\n发送消息及配置confirm\n\n@Testvoid testConfigCallback() throws InterruptedException &#123;    //1.创建cd    CorrelationData cd = new CorrelationData(UUID.randomUUID().toString());    //2.添加confirm callback    cd.getFuture().addCallback(new ListenableFutureCallback&lt;CorrelationData.Confirm&gt;() &#123;        @Override        public void onSuccess(CorrelationData.Confirm result) &#123;            log.debug(&quot;收到confirm callback回执&quot;);            if(result.isAck())&#123;                // 消息发送成功                log.debug(&quot;消息发送成功，收到ack&quot;);            &#125;else &#123;                log.error(&quot;消息发送失败，收到nack,原因：&#123;&#125;&quot; ,result.getReason());            &#125;        &#125;        @Override        public void onFailure(Throwable ex) &#123;            log.error(&quot;消息回调失败&quot;,ex);        &#125;    &#125;);   rabbitTemplate.convertAndSend(&quot;T00.direct&quot;,&quot;red&quot;,&quot;hello&quot;,cd);    Thread.sleep(2000);  //因为需要等待消息发出才能得到回调&#125;\n\n\n运行\n\n所有信息均正确时，返回了ack：\n\n\n\n\n当路由key不正确时，也返回了ack并且返回了我们编写的ReturnCallback配置类（到达交换机，但没有成功路由）：\n\n\n\n\n当无法连接到时，也就是没有正常到达交换机时，返回了nack，同时给出了原因：\n\n\n\n\n连接可靠性：生产者自动重连机制我们不难想到生产者发送消息时，可能会出现网络故障，导致与MQ的连接中断，这样也会导致消息的丢失。\n为了解决这个问题，SpringAMQP提供的消息发送时的重试机制。即：当RabbitTemplate与MQ连接超时后，多次重试。\n修改publisher模块的application.yaml文件，添加下面的内容：\nspring:  rabbitmq:    connection-timeout: 1s # 设置MQ的连接超时时间    template:      retry:        enabled: true # 开启超时重试机制        initial-interval: 1000ms # 失败后的初始等待时间        multiplier: 1 # 失败后下次的等待时长倍数，下次等待时长 = initial-interval * multiplier        max-attempts: 3 # 最大重试次数\n\n也可以看见它的默认值和上面是一样的。\n\n\n我们利用命令停掉RabbitMQ服务：\ndocker stop mq\n\n然后测试发送一条消息，会发现会每隔1秒重试1次，（发送1s发现发送失败，再间隔1s重试，所以两次发送时间间隔2s）总共重试了3次。消息发送的超时重试机制配置成功了！\n\n\n注意：\n\n这个重试是连接时的重试，如果是在消息发送抛出异常时，他是不会充实的。\n当网络不稳定的时候，利用重试机制可以有效提高消息发送的成功率。不过SpringAMQP提供的重试机制是阻塞式的重试，也就是说多次重试等待的过程中，当前线程是被阻塞的。\n如果对于业务性能有要求，建议禁用重试机制。如果一定要使用，请合理配置等待时长和重试次数，当然也可以考虑使用异步线程来执行发送消息的代码。\n\n\n总结为了保证消息在发送的过程中是稳定的，我们采用了生产者确认的方式，\n所谓生产者确认就是使用confirm机制和return回退机制保证消息可以稳定到达队列当中；\nconfirm机制可以通过修改配置文件来生效，它会在消息成功投递到交换机之后返回ack来告知我们它是否到达交换机，如果没有则返回nack；\nreturn回退机制是发生在消息成功投递到交换机之后，这时也会返回ack，但是他将消息路由到队列的过程中可能会失败，这时我们如果还配置了mandatory为ture，MQ就会将消息回调给生产者，否则会直接丢弃这条消息；\n最后我们还可以通过配置confirmcallback和returncallback来设置我们在不同情况下该做什么。\n\n消息持久化为了保证消息在传输的过程中是稳定的，我们需要配置消息持久化，所谓持久化其实就是将MQ存储在内存中的消息写到磁盘上面。\n内存空间有限，当消费者故障或者处理过慢时，会导致消息积压，引发MQ阻塞（mq内存满了之后，会做一个PageOut操作将一些较老的消息转移到磁盘上，这个期间，消息时阻塞的，不能执行其他操作）我们来验证一下，将一条消息发100w次：\n@Testvoid testPageOut()&#123;    Message msg = MessageBuilder            .withBody(&quot;101&quot;.getBytes(StandardCharsets.UTF_8))            .setDeliveryMode(MessageDeliveryMode.NON_PERSISTENT)            .build();    for (int i = 0; i &lt; 1000000; i++) &#123;        rabbitTemplate.convertAndSend(&quot;simple.queue&quot;,msg);    &#125;\n\n可以看见速率出现了明显的低谷，pageout的消息数量也巨大\n\n\n所以实现数据持久化是很有必要的，包括：\n\n交换机持久化\n队列持久化\n消息持久化\n\n实现队列和交换机持久化，都是将Durable设置为true即可；\n消息持久化是在发送消息时附带值为Persistent的properties：\n\n\n\n持久化的消息在mq重启后，消息依旧在\n\n与上面非持久化的消息相比，没有了太大的速率下跌，没有pageout，但是似乎还是不太理想。\n\n\nLazyQueue从RabbitMQ的3.6.0版本开始，就增加了Lazy Queues的模式，也就是惰性队列。惰性队列的特征如下：\n\n接收到消息后直接存入磁盘而非内存\n消费者要消费消息时才会从磁盘中读取并加载到内存（也就是懒加载）\n支持数百万条的消息存储\n\n而在3.12版本之后，LazyQueue已经成为所有队列的默认格式。因此官方推荐升级MQ为3.12版本或者所有队列都设置为LazyQueue模式。\n控制台配置代码配置\n添加x-queue-mod=lazy参数也可设置队列为Lazy模式：\n\n@Beanpublic Queue lazyQueue()&#123;    return QueueBuilder            .durable(&quot;lazy.queue&quot;)            .lazy() // 开启Lazy模式            .build();&#125;\n\n\n当然，我们也可以基于注解来声明队列并设置为Lazy模式：\n\n@RabbitListener(queuesToDeclare = @Queue(        name = &quot;lazy.queue&quot;,        durable = &quot;true&quot;,        arguments = @Argument(name = &quot;x-queue-mode&quot;, value = &quot;lazy&quot;)))public void listenLazyQueue(String msg)&#123;    ....&#125;\n\n测试一遍发现速率 基本一直处于峰值，而且没有在内存中（没有消费者接收这个消息）。\n\n\n总结为了保证消息的持久化，我们要将队列，交换机均设置为持久化的，发出的消息也要是持久化消息，这样就算mq挂了，消息被持久化到了硬盘上，也不会消失。\n\n消费者的可靠性同生产者一样，消费者也需要有确认机制来保证消息能被正常消费。\n消费者确认为了确认消费者是否成功处理消息，RabbitMQ提供了消费者确认机制。即：当消费者处理消息结束后，应该向RabbitMQ发送一个回执，告知RabbitMQ自己消息处理状态。回执有三种可选值：\n\nack：成功处理消息，RabbitMQ从队列中删除该消息\nnack：消息处理失败，RabbitMQ需要再次投递消息\nreject：消息处理失败并拒绝该消息，RabbitMQ从队列中删除该消息\n\nSpringAMQP帮我们实现了消息确认。并允许我们通过配置文件设置ACK处理方式，有三种模式：\n\nnone：不处理。即消息投递给消费者后立刻ack，消息会立刻从MQ删除。非常不安全，不建议使用\nmanual：手动模式。需要自己在业务代码中调用api，发送ack或reject，存在业务入侵，但更灵活\nauto：自动模式。SpringAMQP利用AOP对我们的消息处理逻辑做了环绕增强，当业务正常执行时则自动返回ack.  当业务出现异常时，根据异常判断返回不同结果：\n如果是业务异常，会自动返回nack；\n如果是消息处理或校验异常，自动返回reject;\n\n\n\n实现通过下面的配置可以修改SpringAMQP的ACK处理方式：\nspring:  rabbitmq:    listener:      simple:        acknowledge-mode: none # 不做处理\n\n修改consumer服务的SpringRabbitListener类中的方法，模拟一个消息处理的异常：\n@RabbitListener(queues = &quot;simple.queue&quot;)public void listenSimpleQueueMessage(String msg) throws InterruptedException &#123;      log.info(&quot;消费者接收到消息：&quot; + msg );      throw new MessageConversionException(&quot;故意的&quot;);&#125;\n\n测试可以发现：当消息处理发生异常时，消息依然被RabbitMQ删除了。\n我们再次把确认机制修改为auto：\nspring:  rabbitmq:    listener:      simple:        acknowledge-mode: auto # 自动ack\n\n在异常位置打断点，再次发送消息，程序卡在断点时，可以发现此时消息状态为unacked（未确定状态）：\n\n\n\n消费者处理消息后可以向MQ发 送ack回执，MQ收到ack回执后才会删除该消息。\n\n但是当消费者出现异常后，消息会不断requeue（重入队）到队列，再重新发送给消费者。如果消费者再次执行依然出错，消息会再次requeue到队列，再次投递，直到消息处理成功为止。\n极端情况就是消费者一直无法执行成功，那么消息requeue就会无限循环，导致mq的消息处理飙升，带来不必要的压力，我们刚刚在验证auto模式时，就发现了一条消息也可以达到惊人的数据流量。\n为了应对上述情况Spring又提供了消费者失败重试机制：在消费者出现异常时利用本地重试，而不是无限制的requeue到mq队列。\n消费失败重试修改consumer服务的application.yml文件，添加内容：\nspring:  rabbitmq:    listener:      simple:        retry:          enabled: true # 开启消费者失败重试          initial-interval: 1000ms # 初识的失败等待时长为1秒          multiplier: 1 # 失败的等待时长倍数，下次等待时长 = multiplier * last-interval          max-attempts: 3 # 最大重试次数          stateless: true # true无状态；false有状态。如果业务中包含事务，这里改为false\n\n重启consumer服务，重复之前的测试。可以发现：\n\n消费者在失败后消息没有重新回到MQ无限重新投递，而是在本地重试了3次\n本地重试3次以后，抛出了AmqpRejectAndDontRequeueException异常。查看RabbitMQ控制台，发现消息被删除了，说明最后SpringAMQP返回的是reject\n\n结论：\n\n开启本地重试时，消息处理过程中抛出异常，不会requeue到队列，而是在消费者本地重试\n重试达到最大次数后，Spring会返回reject，消息会被丢弃\n\n\n异常交换机&#x2F;队列本地测试达到最大重试次数后，消息会被丢弃。这在某些对于消息可靠性要求较高的业务场景下，显然不太合适了。因此Spring允许我们自定义重试次数耗尽后的消息处理策略，这个策略是由MessageRecovery接口来定义的，它有3个不同实现：\n\nRejectAndDontRequeueRecoverer：重试耗尽后，直接reject，丢弃消息。默认就是这种方式 \nImmediateRequeueMessageRecoverer：重试耗尽后，返回nack，消息重新入队 \nRepublishMessageRecoverer：重试耗尽后，将失败消息投递到指定的交换机\n\n比较优雅的一种处理方案是RepublishMessageRecoverer，失败后将消息投递到一个指定的，专门存放异常消息的队列，后续由人工集中处理。\n\n\n\n在consumer服务中定义处理失败消息的交换机和队列\n\n@Beanpublic DirectExchange errorMessageExchange()&#123;    return new DirectExchange(&quot;error.direct&quot;);&#125;@Beanpublic Queue errorQueue()&#123;    return new Queue(&quot;error.queue&quot;, true);&#125;@Beanpublic Binding errorBinding(Queue errorQueue, DirectExchange errorMessageExchange)&#123;    return BindingBuilder.bind(errorQueue).to(errorMessageExchange).with(&quot;error&quot;);&#125;\n\n\n定义一个RepublishMessageRecoverer，关联队列和交换机\n\n@Beanpublic MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate)&#123;    return new RepublishMessageRecoverer(rabbitTemplate, &quot;error.direct&quot;, &quot;error&quot;);&#125;\n\n\n运行\n\n最后可以看见，在接收三次消息之后，它将消息发给了error.queue里面还附带了全部的异常信息\n\n\n\n\n总结为了保证消费者的可靠性，首先我们通过消费者确认机制，消费者返回ack时，mq将消息删除；\n返回nack时，表示消息处理异常，为例减少服务器负担，我们在此基础上增加消费者重试机制，并声明异常交换机和异常处理器，将这些消息投递并路由到其中，最后由人工统一处理。\n\n如何保证消息的可靠性？消息从生产者一直到消费者被其消费的过程中，每个阶段都有可能导致消息的丢失，从而使业务异常，我们要从三个方面保证消息的可靠性：\n\n要保证生产者的可靠性：首先要通过confirm机制和return回调机制来实现生产者确认功能；confirm机制会在消息成功投递到交换机之后，返回ack，反之nack，来使消息投递到交换机的过程可感知化；但是消息成功投递到交换机中并不代表可以成功路由到队列上，所以还需要return回调机制来保证消息可以顺利路由到队列中；同时我们还可以定义confirmcallback和returncallback来设置不同情况下，我们应该做什么。\n要使消息持久化：消息持久化需要交换机，队列和消息本身都经过持久化，这样才可以把消息存储在磁盘上，即使mq挂掉，消息也不会消失。\n要保证消费者的可靠性：首先和生产者一样，我们使用消费者确认机制，在消息被成功消费之后返回ack，来通知mq这条消息可以删除，反之返回nack；但是为了业务的完整性，我们又使用消费者重试机制，保证消息可以被正常消费，同时又不过多占用服务器性能；在重试过后，我们可以设置一对异常处理交换器和队列，专门将重试过后但又没有被消费的消息统一管理起来，最后通过人工处理。\n\n至此，可以基本保证消息的可靠性。\n","categories":["MQ"],"tags":["MQ"]},{"title":"消息的幂等性","url":"/2025/07/28/%E6%B6%88%E6%81%AF%E7%9A%84%E5%B9%82%E7%AD%89%E6%80%A7/","content":"幂等性是什么幂等是一个数学概念，用函数表达式来描述是这样的：f(x) = f(f(x))，例如求绝对值函数。\n放在业务中，幂等就是i同一条消息被重复消费多次，业务结果只会被执行一次，不会引发副作用（如重复扣库存、重复发优惠券、重复扣款等），一句话就是指同一个业务，执行一次或多次对业务状态的影响是一致的。\n为什么要保证幂等性但数据的更新往往不是幂等的，如果重复执行可能造成不一样的后果。比如：\n\n取消订单，恢复库存的业务。如果多次恢复就会出现库存重复增加的情况\n退款业务。重复退款对商家而言会有经济损失。\n\n所以，我们要尽可能避免业务被重复执行。\n但是RabbitMQ 或任何 MQ 都不能 100% 保证只投递一次或只消费一次，可能因为：\n\n消息重复投递\n消息可能重新进入队列\n消息可能重复消费\n\n等等原因….\n所以在业务层保证幂等性显得尤为重要。\n如何保证幂等性数据库唯一约束如果从MQ拿到数据是要存到数据库，那么可以根据数据（创建一个UUID）创建唯一约束；这样的话，同样的数据从MQ发送过来之后，当插入数据库的时候，会报违反唯一约束的异常，不会插入成功的。\n\n每条消息携带唯一 ID（如 messageId、订单号）\n数据库建表并为 messageId 设置唯一约束：\n\nCREATE TABLE message_log (  message_id VARCHAR(64) PRIMARY KEY,  ...);\n\n\n消费者处理消息时，尝试插入 messageId：\n\n\n插入成功：说明是第一次处理 → 执行业务\n插入失败：违反唯一约束 → 表示已处理，跳过\n\n消息唯一id在生产者发送消息时，创建一个全局唯一id，在消费的时候，都先去redis里面查询是否有这个id，如果没有就执行业务插入id，如果有了，就跳过不执行业务。\n\nRedis 的 setIfAbsent 是原子操作，线程安全\n可设置过期时间，释放空间\n更适合高并发、轻量级幂等\n\n二者的共性及区别\n其实两种实现的基础都是在一个唯一id上，所以他们的共性就是在生成id上，这里我提供一种id的生成方式。\n\n共性我们翻阅源码，发现在消息转换器的底层中有这样一段：\n消息转换器的底层其实自动生成过一个id，我们只需要把CreateMessageIds的值设置为true即可使用。\n所以我们将之前的消息转换器改造一下：\n@Beanpublic MessageConverter messageConverter()&#123;    // 1.定义消息转换器    Jackson2JsonMessageConverter jjmc = new Jackson2JsonMessageConverter();    // 2.配置自动创建消息id，用于识别不同消息，也可以在业务中基于ID判断是否是重复消息    jjmc.setCreateMessageIds(true);    return jjmc;&#125;\n\n首先我们先不改变消息转换器，发送一条消息，然后改造之后再发送一条同样的消息。\n现在来测试一下:\n发现了改造之后的消息，携带了一个id!!\n\n\n这样唯一id的生成就搞定了。\n区别总结如下：\n\n\n\n比较项\n使用唯一 ID（Redis 去重）\n数据库唯一约束\n\n\n\n核心机制\n判断消息 ID 是否存在于 Redis\n利用数据库插入唯一值是否成功\n\n\n幂等性实现方式\n内存缓存去重\n主键&#x2F;唯一索引去重\n\n\n性能\n高性能，适合高并发场景\n有 IO 开销，适合稳定场景\n\n\n数据可追溯\n不可查历史\n可查历史处理记录\n\n\n存储压力\n小（可设置过期）\n大（需定期清理）\n\n\n事务一致性\nRedis 与业务逻辑分离\n可与业务逻辑在同一事务\n\n\n风险容错\nRedis 宕机可能丢幂等状态\n数据库更稳定\n\n\n总结实现消息的幂等性，我们可以有两种策略：\n\n使用数据库的唯一约束实现，从MQ中拿到消息是要将数据插入数据库，这个过程中可以把证明消息唯一的id设置为数据库的唯一约束；同样的数据插入数据库时，如果这个唯一约束已经存在，那就无法进行，如果时第一次，就可以顺利插入，从而实现了消息的幂等性。\n使用消息唯一id搭配redis，生产者每次发送消息时，生成一个全局唯一id；执行业务逻辑之前，我们都先查看redis中是否存在有这个唯一id；如果有，证明业务逻辑已经执行过，跳过不执行，反之执行，即可。\n\n","categories":["MQ"],"tags":["MQ"]},{"title":"消息的顺序性","url":"/2025/07/28/%E6%B6%88%E6%81%AF%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%80%A7/","content":"消息的顺序性错乱在业务中，可能会有对某个订单的增删改操作，比如有三条sql执行顺序是增加、修改、删除；消费者换了顺序给执行成删除、修改、增加，这样能行吗？\n肯定是不行的。\nRabbitMQ对于 RabbitMQ 来说，导致上面顺序错乱的原因通常是消费者是集群部署，不同的消费者消费到了同一订单的不同的消息，虽然消费者从MQ里面读取数据是有序的，但是可能因为每个消费者性能不同导致执行的顺序不同。\n如消费者 A 执行了增加，消费者 B 执行了修改，消费者 C 执行了删除，但是消费者 C 执行比消费者 B 快，消费者 B 又比消费者 A 快，就会导致执行到数据库的时候顺序错乱，本该顺序是增加、修改、删除，变成了删除、修改、增加。\n如图：\n\n\n\n\n如何保证消息的顺序性RabbitMQRabbitMQ 的问题是由于不同的消息都发送到了同一个queue中，多个消费者都消费同一个queue的消息。\n解决这个问题：\n\n我们可以给RabbitMQ创建多个queue，每个消费者固定消费一个queue的消息；\n生产者发送消息的时候，同一个订单号的消息发送到同一个queue中；\n由于同一个queue的消息是一定会保证有序的，那么同一个订单号的消息就只会被一个消费者顺序消费，从而保证了消息的顺序性。\n\n如图：\n\n\n\n会使队列变多, 造成吞吐量下降，但是这种可以在消费者内部采用多线程的方式去消费。\n\n总结RabbitMQ由于消费者的集群部署，同一个队列中的消息可能会被多个消费者消费，而每个消费者的性能不同，使用最终执行的顺序可能和我们预期的不同；\n我们可以采用创建多个queue的方式，一个业务的消息只发给某一个队列，这一个队列也只由一个消费者消费，由于队列内的消息是有序的，所以消费者消费的顺序也是有序的；\n只是这样会造成吞吐量的下降，但是我们可以在消费者内部采用多线程的方式消费。\n","categories":["MQ"],"tags":["MQ RabbitMQ"]},{"title":"RabbitMQ","url":"/2025/07/26/RabbitMQ/","content":"基本概念消息Broker，目前常见的实现方案就是消息队列（MessageQueue），简称为MQ。\nRabbitMQ是基于Erlang语言开发的开源消息通信中间件，官网地址：Messaging that just works — RabbitMQ\n安装过程网上有很多，在此我就省略了。\n\n\n\n其中包含几个概念：\n\npublisher：生产者，也就是发送消息的一方\nconsumer：消费者，也就是消费消息的一方\nqueue：队列，存储消息。生产者投递的消息会暂存在消息队列中，等待消费者处理\nexchange：交换机，负责消息路由。生产者发送的消息由交换机决定投递到哪个队列。\nvirtual host：虚拟主机，起到数据隔离的作用。每个虚拟主机相互独立，有各自的exchange、queue\n\n整个过程梳理下来如下：\n生产者[发送消息给交换机，交换机路由消息（并不是存储），然后决定将消息投递到某个或者某些队列]，这时，队列存储这些消息，等待消费者处理，消费者根据自身的需求和能力选择处理消息。\n\n注意：中括号内并不是必须的操作。\n\n在同一个mq集群下，可以有多个virtual host，他们之间互相隔离，有各自的exchange、queue。\n\n发送消息上面我们了解了基本过程，我们就来演示一下。\n\n创建两个queue\n\n\n\n如下：\n\n\n\n操作交换机发出消息\n\n我们将amq.fanout绑定我们刚刚创建的两个队列，并发送消息Hello,mq!。\n\n\n消息已发送！\n\n\n\n成功接收消息\n\n\n\n也可以看见消息的具体内容，也可以发现这里的消息无法更改\n\n\n\n数据隔离上面所说同一个mq集群下，可以有多个virtual host，他们之间互相隔离，有各自的exchange、queue。\n我们也可以进行验证。\n\n创建一个T00超级管理员\n\n\n\n但是这个时候，我们无法操作，队列，交换机等，因为“没有我们名下”的虚拟主机。\n\n创建虚拟主机\n\n切换成我们新创建的用户，然后创建一个虚拟主机\n\n\n他们两个虚拟主机的数据是相互隔离的\n\n\n\nSpringAMQP将来我们开发业务功能的时候，肯定不会在控制台收发消息，而是应该基于编程的方式。由于RabbitMQ采用了AMQP协议，因此它具备跨语言的特性。任何语言只要遵循AMQP协议收发消息，都可以与RabbitMQ交互。并且RabbitMQ官方也提供了各种不同语言的客户端。\n\n\n查看官方文档，java操作MQ的hello，world都及其复杂\n\n\n\n\nSpring的官方刚好基于RabbitMQ提供了这样一套消息收发的模板工具：SpringAMQP。并且还基于SpringBoot对其实现了自动装配，使用起来非常方便。\n入门案例\n引入相关依赖\n\n使用SpringAMQP，我们要先引入相关依赖（这里是在父工程中引入的）\n&lt;!--AMQP依赖，包含RabbitMQ--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt;\n\n我们以它为父工程创建两个微服务模块来模拟消息的收发过程。\n\n\n\n配置RabbitMQ服务端信息\n\n为了方便测试，我们先新建一个simple.queue\n先配置MQ地址，在publisher服务的application.yml中添加配置\nspring:  rabbitmq:    host: 192.168.100.128 # 你的虚拟机IP    port: 5672 # 端口    virtual-host: /T00 # 虚拟主机    username: TOO # 用户名    password: 101 # 密码\n\n\n发送消息\n\nspringAMQP中封装了一个RabbitTemplate工具类，我们可以直接使用工具类来发送消息。\n@Autowiredprivate RabbitTemplate rabbitTemplate;@Testvoid testSendMessage2Queue()&#123;    String queueName = &quot;simple.queue&quot;;    String msg = &quot;helloe,mq!&quot;;    rabbitTemplate.convertAndSend(queueName,msg);&#125;\n\n直接运行，可以在控制台中找到发送的消息\n\n\n\n接收消息\n\nspringAMQP中封装了一个注解，直接在注解中queues数组中指定需要监听的队列名字即可\n@RabbitListener(queues = &quot;simple.queue&quot;)public void listenerSimpleQueue(String msg)&#123;        System.out.println(&quot;收到了消息：&quot;+ msg);    &#125;\n\n运行之后成功收到了消息\n\n\n\n这里被注解的方法的参数类型应和生产者的一致，@RabbitListener注解的作用就是将接收到的消息封装在方法的参数中。\n\n\nWorkQueues模型Work queues，任务模型。简单来说就是让多个消费者绑定到一个队列，共同消费队列中的消息，每个消息只会被一个消费者处理一次，用来实现任务的“分工处理”。\n\n\n当消息处理比较耗时的时候，可能生产消息的速度会远远大于消息的消费速度。长此以往，消息就会堆积越来越多，无法及时处理。\n此时就可以使用work 模型，多个消费者共同处理消息处理，消息处理的速度就能大大提高了。\n接下来，我们就来模拟这样的场景。\n首先，我们在控制台创建一个新的队列，命名为work.queue：\n\nRabbitMQ 有两种分发模式：\n\n默认轮询发配\n\n公平发配\n\n\n\n\n我们首先模拟轮询发配\n轮询发配两个消费者性能相同\n消息发送\n\n@Testvoid testWorkQueue() throws InterruptedException &#123;    String queueName = &quot;work.queue&quot;;    for (int i = 1; i &lt;= 50; i++) &#123;        String msg = &quot;hello,worker!,message_&quot; + i;        rabbitTemplate.convertAndSend(queueName,msg);        Thread.sleep(20);    &#125;&#125;\n\n\n消息接收\n\n要模拟多个消费者绑定同一个队列，我们在consumer服务的SpringRabbitListener中添加2个新的方法：\n@RabbitListener(queues = &quot;work.queue&quot;)public void listenerWorkQueue1(String msg)&#123;    System.out.println(&quot;消费者1 收到了消息：&quot; + msg);&#125;@RabbitListener(queues = &quot;work.queue&quot;)public void listenerWorkQueue2(String msg)&#123;    System.err.println(&quot;消费者1 收到了消息：&quot; + msg);&#125;\n\n\n运行\n\n\n\n可以看见，两个消费者如果性能一致时类似于轮询，一人消费一条消息，将消息均分了。\n两个消费者性能不同让两个消费者接收消息后停顿不同时间来实现模拟性能不同，消费者1每秒可以处理50条消息，而消费者2只能处理5条。\n@RabbitListener(queues = &quot;work.queue&quot;)public void listenerWorkQueue1(String msg) throws InterruptedException &#123;    System.out.println(&quot;消费者1 收到了消息：&quot; + msg);    Thread.sleep(20);&#125;@RabbitListener(queues = &quot;work.queue&quot;)public void listenerWorkQueue2(String msg) throws InterruptedException &#123;    System.err.println(&quot;消费者2 收到了消息：&quot; + msg);    Thread.sleep(200);&#125;\n\n结果如下：\n\n\n\n\n可以看见他们还是均分了50条消息，后面的时间全是性能比较差的消费者2在处理，性能好的消费者1反倒空闲了。\n这样显然是不合理的，浪费了系统的性能，这时我们就应该使用公平分配模式。\n公平分配公平分配通俗来讲，就是能者多劳。\n在spring中有一个简单的配置，可以解决这个问题。我们修改consumer服务的application.yml文件，添加配置：\nspring:  rabbitmq:    listener:      simple:        prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息\n\n这样配置之后再次运行：\n\n\n可以发现，由于消费者1处理速度较快，所以处理了更多的消息；消费者2处理速度较慢，只处理了6条消息。而最终总的执行耗时也在1秒左右，大大提升。\n这样充分利用了每一个消费者的处理能力，可以有效避免消息积压问题。\n\n交换机Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！\n交换机的类型有四种：\n\nFanout：广播，将消息交给所有绑定到交换机的队列。我们最早在控制台使用的正是Fanout交换机。\nDirect：订阅，基于RoutingKey（路由key）发送给订阅了消息的队列\nTopic：通配符订阅，与Direct类似，只不过RoutingKey可以使用通配符\nHeaders：头匹配，基于MQ的消息头匹配，用的较少。\n\n接下来，我们就来一一验证。\nFanout\n准备工作\n\n\n创建一个名为 T00.fanout的交换机，类型是Fanout\n创建两个队列fanout.queue1和fanout.queue2，绑定到交换机T00.fanout\n\n\n\n过程和上面控制台发送消息一样，就略过了。\n\n消息发送\n\nfanout交换机没有这个key，传入一个空字符串即可：\n\n\n@Testpublic void testFanoutExchange() &#123;    // 交换机名称    String exchangeName = &quot;T00.fanout&quot;;    // 消息    String message = &quot;hello, everyone!&quot;;    rabbitTemplate.convertAndSend(exchangeName, &quot;&quot;, message);&#125;\n\n\n消息接收\n\n@RabbitListener(queues = &quot;fanout.queue1&quot;)public void listenerFanoutQueue1(String msg)&#123;    System.out.println(&quot;消费者1 收到了fanout.queue1消息：&quot; + msg);&#125;@RabbitListener(queues = &quot;fanout.queue2&quot;)public void listenerFanoutQueue2(String msg)&#123;    System.out.println(&quot;消费者2 收到了fanout.queue2消息：&quot; + msg);&#125;\n\n\n运行\n\n两者均接收到了消息，就如同广播一样，在广播的范围内，每个人都能收到消息。\n\n\n\nDirect在Fanout交换机中，一条消息，会被所有订阅的队列都消费。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。\nDirect交换机有以下特点：\n\n队列与交换机的绑定：不能是任意绑定了，而是要指定一个RoutingKey（路由key）\n\n消息的发送方在向 Exchange发送消息时，也必须指定消息的 RoutingKey\n\nExchange会根据绑定队列的Routingkey和所路由消息的Routingkey是否匹配，进行消息的发送，也就是是说只有队列的Routingkey与消息的 Routing key完全一致，才会接收到消息。\n\n\n\n接下来我们进行演示：\n\n准备工作\n\n\n创建一个名为T00.direct的交换机，类型是direct\n再分别创建一个Routing key为“red”，“blue”的direct.queue1和一个Routing key为“red”，“yellow”的direct.queue2\n\n\n\n\n消息发送\n\n@Testpublic void testSendDirectExchange() &#123;    // 交换机名称    String exchangeName = &quot;T00.direct&quot;;    // 消息    String message = &quot;红色&quot;;    rabbitTemplate.convertAndSend(exchangeName, &quot;red&quot;, message);&#125;\n\n@Testpublic void testSendDirectExchange() &#123;    // 交换机名称    String exchangeName = &quot;T00.direct&quot;;    // 消息    String message = &quot;蓝色&quot;;    rabbitTemplate.convertAndSend(exchangeName, &quot;bule&quot;, message);&#125;\n\n\n消息接收\n\n@RabbitListener(queues = &quot;direct.queue1&quot;)public void listenerDirectQueue1(String msg)&#123;    System.out.println(&quot;消费者1 收到了direct.queue1消息：&quot; + msg);&#125;@RabbitListener(queues = &quot;direct.queue2&quot;)public void listenerDirectQueue2(String msg)&#123;    System.out.println(&quot;消费者2 收到了direct.queue2消息：&quot; + msg);&#125;\n\n\n运行\n\n如果是red，他们都可以收到\n\n\n但是如果是blue，就只有2才能收到\n\n\n\nTopic其实Topic与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列，唯一的区别就是Topic可以让队列在绑定BindingKey 的时候使用通配符。\nBindingKey 一般都是有一个或多个单词组成，多个单词之间以.分割，例如： item.insert\n通配符规则：\n\n#：匹配一个或多个词\n*：只能匹配1个词\n\n举例：\n\nitem.#：能够匹配item.spu.insert 或者 item.spu\nitem.*：只能匹配item.spu\n\n现在我们来实现一下：\n\n\n准备工作\n\n假如此时publisher发送的消息使用的RoutingKey共有四种：\n\nchina.news 代表有中国的新闻消息；\nchina.weather 代表中国的天气消息；\njapan.news 则代表日本新闻\njapan.weather 代表日本的天气消息；\n\n解释：\n\ntopic.queue1绑定的是china.# ，凡是以 china.开头的routing key 都会被匹配到，包括：\nchina.news\nchina.weather\n\n\ntopic.queue2绑定的是#.news ，凡是以 .news结尾的 routing key 都会被匹配。包括:\nchina.news\njapan.news\n\n\n\n\n\n\n发送消息\n\n@Testpublic void testSendTopicExchange() &#123;    // 交换机名称    String exchangeName = &quot;T00.topic&quot;;    // 消息    String message = &quot;*****&quot;;    rabbitTemplate.convertAndSend(exchangeName, &quot;***&quot;, message);&#125;\n\n\n接收消息\n\n@RabbitListener(queues = &quot;topic.queue1&quot;)public void listenerTopicQueue1(String msg)&#123;    System.out.println(&quot;消费者1 收到了topic.queue1消息：&quot; + msg);&#125;@RabbitListener(queues = &quot;topic.queue2&quot;)public void listenerTopicQueue2(String msg)&#123;    System.out.println(&quot;消费者2 收到了topic.queue2消息：&quot; + msg);&#125;\n\n\n运行\n\nroutingKey为japan.news时，只有消费者2收到了消息\n\n\nroutingKey为china.news时，都收到了消息\n\n\nroutingKey为china.wether时，只有消费者1收到了消息\n\n\n符合我们的推测。\n\n声明队列和交换机在之前我们都是基于RabbitMQ控制台来创建队列、交换机。但是在实际开发时，队列和交换机是程序员定义的，将来项目上线，又要交给运维去创建。那么程序员就需要把程序中运行的所有队列和交换机都写下来，交给运维。在这个过程中是很容易出现错误的。\n因此推荐的做法是由程序启动时检查队列和交换机是否存在，如果不存在自动创建。\n基本APISpringAMQP提供了一个Queue类，用来创建队列：\n\n\nSpringAMQP还提供了一个Exchange接口，来表示所有不同类型的交换机：\n\n\n我们可以自己创建队列和交换机，不过SpringAMQP还提供了ExchangeBuilder来简化这个过程：\n\n\n而在绑定队列和交换机时，则需要使用BindingBuilder类来创建Binding对象：\n\n\n\n一般这些的声明都在消费者中\n\n\n我们有两种方法声明队列和交换机\n\nnew一个对应的类，在后面指出名字即可\n\n调用builder函数\n\n\n下面我们共同使用两种办法来声明交换机和队列以及他们的绑定关系。\nfanout@Configurationpublic class FanoutConfiguration &#123;    /**     * 声明交换机     * @return Fanout类型交换机     */    @Bean    public FanoutExchange fanoutExchange()&#123;        // ExchangeBuilder.fanoutExchange(&quot;TOO.fanout2&quot;).build();        return new FanoutExchange(&quot;TOO.fanout2&quot;);  //默认持久，至于什么是持久，下面一篇文章会进行讲解    &#125;    /**     * 第1个队列     */    @Bean    public Queue fanoutQueue3()&#123;        return new Queue(&quot;fanout.queue3&quot;);  //默认持久    &#125;    /**     * 绑定队列和交换机     */    @Bean    public Binding bindingQueue1(Queue fanoutQueue3, FanoutExchange fanoutExchange)&#123;        return BindingBuilder.bind(fanoutQueue3).to(fanoutExchange);    &#125;    /**     * 第2个队列     */    @Bean    public Queue fanoutQueue4()&#123;        return new Queue(&quot;fanout.queue4&quot;);    &#125;    /**     * 绑定队列和交换机     */    @Bean    public Binding bindingQueue2(Queue fanoutQueue4, FanoutExchange fanoutExchange)&#123;        return BindingBuilder.bind(fanoutQueue4).to(fanoutExchange);    &#125;&#125;\n\n\n运行之后，交换机、队列、绑定关系都成功声明了。\n\n\n\n\n\n\n\n\ndirect对于一个direct的交换机进行绑定操作会显得比较繁琐（因为builder函数一次只能设置一个key）\n@Configurationpublic class DirectConfiguration &#123;    /**     * 声明交换机     * @return Direct类型交换机     */    @Bean    public DirectExchange directExchange()&#123;        return ExchangeBuilder.directExchange(&quot;TOO.direct&quot;).build();    &#125;    /**     * 第1个队列     */    @Bean    public Queue directQueue1()&#123;        return new Queue(&quot;direct.queue1&quot;);    &#125;    /**     * 绑定队列和交换机     */    @Bean    public Binding bindingQueue1WithRed(Queue directQueue1, DirectExchange directExchange)&#123;        return BindingBuilder.bind(directQueue1).to(directExchange).with(&quot;red&quot;);    &#125;    /**     * 绑定队列和交换机     */    @Bean    public Binding bindingQueue1WithBlue(Queue directQueue1, DirectExchange directExchange)&#123;        return BindingBuilder.bind(directQueue1).to(directExchange).with(&quot;blue&quot;);    &#125;    /**     * 第2个队列     */    @Bean    public Queue directQueue2()&#123;        return new Queue(&quot;direct.queue2&quot;);    &#125;    /**     * 绑定队列和交换机     */    @Bean    public Binding bindingQueue2WithRed(Queue directQueue2, DirectExchange directExchange)&#123;        return BindingBuilder.bind(directQueue2).to(directExchange).with(&quot;red&quot;);    &#125;    /**     * 绑定队列和交换机     */    @Bean    public Binding bindingQueue2WithYellow(Queue directQueue2, DirectExchange directExchange)&#123;        return BindingBuilder.bind(directQueue2).to(directExchange).with(&quot;yellow&quot;);    &#125;&#125;\n\nholy shit，这种声明方式好麻烦，因此伟大的springAMQP中还提供了一种注解声明队列和交换机的方法。\n\n注解声明可以在消费者注解中用bindings参数来声明队列，交换机和绑定关系，具体参数如下：\n\n\n基本框架如下：\n@RabbitListener(bindings = @QueueBinding(        value = @Queue(),        exchange = @Exchange(),        key = &#123;&#125;))\n\n我们现在删除以前于direct相关的交换机和队列，来试试用注解声明：\n@RabbitListener(bindings = @QueueBinding(        value = @Queue(name = &quot;direct.queue1&quot;,durable = &quot;true&quot;),        exchange = @Exchange(name = &quot;T00.direct&quot;,type = ExchangeTypes.DIRECT),        key = &#123;&quot;red&quot; , &quot;blue&quot;&#125;))public void listenerDirectQueue1(String msg)&#123;    System.out.println(&quot;消费者1 收到了direct.queue1消息：&quot; + msg);&#125;\n\n@RabbitListener(bindings = @QueueBinding(        value = @Queue(name = &quot;direct.queue2&quot;,durable = &quot;true&quot;),        exchange = @Exchange(name = &quot;T00.direct&quot;,type = ExchangeTypes.DIRECT),        key = &#123;&quot;red&quot; , &quot;yellow&quot;&#125;))public void listenerDirectQueue2(String msg)&#123;    System.out.println(&quot;消费者2 收到了direct.queue2消息：&quot; + msg);&#125;\n\n运行之后可以看见成功的创建了。\n\n\n\n消息转换器前面我们说到生产者发送消息的类型最好与消费者参数的类型相同，但是那是接收消息，那发送消息是否有什么限定呢？\n默认消息转换器我们先来试试它默认的消息转换器\n\n创建一个object.queue队列用于接收\n编写一个testSendObject()用于发送消息（json格式）\n\n@Testpublic void testSendObject() &#123;    Map&lt;String,Object&gt; msg = new HashMap&lt;&gt;();    msg.put(&quot;name&quot;,&quot;jack&quot;);    msg.put(&quot;age&quot;,18);    rabbitTemplate.convertAndSend(&quot;object.queue&quot;,msg);&#125;\n\n在发送消息过后，我们来到mq的控制台查看接收到的消息：\n\n\n它并不是json格式的信息，反而是一堆看不懂的东西，这是为什么呢？\n因为它默认的消息转换器是将消息jdk序列化，jdk序列化存在安全漏洞，可读性比较差（如果以后发送的消息是一个体积很大，很复杂的json，jdk序列化的消息很难维护）的缺点，那我们有没有什么方法可以解决呢？\n答案就是我们自己配置消息转换器来替换默认的转换器。\n配置JSON转换器\n在publisher和consumer两个服务中都引入依赖（父工程中引入即可）：\n\n&lt;dependency&gt;    &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt;    &lt;artifactId&gt;jackson-dataformat-xml&lt;/artifactId&gt;    &lt;version&gt;2.9.10&lt;/version&gt;&lt;/dependency&gt;\n\n注意，如果项目中引入了spring-boot-starter-web依赖，则无需再次引入Jackson依赖。\n\n配置消息转换器：\n\n在publisher和consumer两个服务的启动类中添加一个Bean即可：\n@Beanpublic MessageConverter jacksonmessageConverter()&#123;    return new Jackson2JsonMessageConverter();&#125;\n\n再次发送，成功转换了\n\n\n\n\n\n\n\n\n\n\n","categories":["MQ"],"tags":["MQ"]},{"title":"消息积压的处理方法","url":"/2025/07/29/%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/","content":"消息积压的原因MQ 执行有三大阶段：\n\n消息生产阶段。\n消息存储阶段。\n消息消费阶段。\n\n很显然，消息堆积是出现在第三个消息消费阶段的。\n当生产者发送消息的速度超过了消费者处理消息的速度, 或者如果消费者因为某些原因持续阻塞，就会导致队列中的消息堆积，直到队列存储消息达到上限。最早接收到的消息，可能就会成为死信，会被丢弃，这就是消息积压问题\n解决办法如果仅仅是消息堆积，而且发现的及时\n增加更多消费者；\n提高消费速度提高单个消息者的处理能力：在消费者内开启线程池加快消息处理速度；\n使用限流手段，限制生产者生产消息的速度。\n\n如果是bug\n先修好消费者的bug，但是这个时间一般比较久，数据积压严重；\n我们提前建好10倍队列，再编写一个专门用于分发消息的消费者，停掉原来的消费者，用新的消费者将消息发给队列保存；\n最后消息处理完毕之后，寻找服务器空闲时间重新消费消息。\n\n","categories":["MQ"],"tags":["MQ RabbitMQ"]},{"title":"死信以及延迟消息","url":"/2025/07/28/%E6%AD%BB%E4%BF%A1%E4%BB%A5%E5%8F%8A%E5%BB%B6%E8%BF%9F%E6%B6%88%E6%81%AF/","content":"什么是死信死信，顾名思义就是无法被消费的消息. 当一个队列中的消息满足下 列情况之一时，可以成为死信（dead letter):\n当一个队列中的消息满足下列情况之一时，可以成为死信（dead letter）：\n\n消费者不要了（消费者使用basic.reject或 basic.nack声明消费失败，并且消息的requeue参数设置为false）。\n消息过期了（超过了队列或消息本身设置的过期时间）。\n投递的队列消息满了，最早的消息可能成为死信。\n\n如果一个队列中的消息已经成为死信，并且这个队列通过dead-letter-exchange属性指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机就称为死信交换机（Dead Letter Exchange ——DLX）。\n死信队列（Dead Letter Queue，简称 DLQ）是用于接收无法被正常消费的消息的一种特殊队列机制，RabbitMQ 提供死信交换机（DLX）来处理这些消息。\n他们之间的关系是这样的：死信 ➝ DLX ➝ routingKey ➝ 死信队列（DLQ）\n那他们有什么作用呢？\n\n收集那些因处理失败而被拒绝的消息\n收集那些因队列满了而被拒绝的消息\n1，2点其实就是对消费者异常处理的兜底手段\n\n\n收集因TTL（有效期）到期的消息（这个作用就可以让我们实现延迟消息的功能）\n\n\n延迟消息试想电影院购票、高铁购票，下单后就会锁定座位资源，其他人无法重复购买。\n但是这样就存在一个问题，假如用户下单后一直不付款，就会一直占有库存资源，导致其他客户无法正常交易，最终导致商户利益受损！\n因此，电商中通常的做法就是：对于超过一定时间未支付的订单，应该立刻取消订单并释放占用的库存。\n例如，订单支付超时时间为30分钟，则我们应该在用户下单后的第30分钟检查订单支付状态，如果发现未支付，应该立刻取消订单，释放库存。\n但问题来了：如何才能准确的实现在下单后第30分钟去检查支付状态呢？\n像这种在一段时间以后才执行的任务，我们称之为延迟任务，而要实现延迟任务，最简单的方案就是利用MQ的延迟消息了。\n在RabbitMQ中实现延迟消息也有两种方案：\n\n死信交换机+TTL（可以是队列的TTL也可以是消息本身的TTL）\n延迟消息插件\n\nDLX + TTL我们先缕清一下思路\n\n\n\n首先，生产者发送一个具有TTL（expiration属性决定）的消息给一个simple.direct，它会将消息发送给由dead-letter-exchange属性指定了死信交换机的simple.queue。\n这时消息因为没有消费者，所有会一直存在于simple.queue，一旦到达TTL所限制的时间，它就会成为死信，从而进入死信交换机dlx.direct。\n最后死信交换机将消息给dlx.queue，然后由对应的消费者处理延迟消息。\n\n\n我们编写好生产者和消费者的代码，验证一下\n\n生产者\n\n@Testvoid testSendTTLMessage2Queue()&#123;    Message msg = MessageBuilder            .withBody(&quot;101&quot;.getBytes(StandardCharsets.UTF_8))            .setExpiration(&quot;10000&quot;)            .build();    rabbitTemplate.convertAndSend(&quot;simple.direct&quot;,&quot;&quot;,msg);    log.info(&quot;我已发送消息&quot;);&#125;\n\n\n消费者\n\n@RabbitListener(queues = &quot;dlx.queue&quot;)public void listenerDlxQueue(String msg)&#123;    log.info(&quot;延时消费者接收到消息：&quot; + msg );&#125;\n\n\n运行\n\n\n\n可以看到，两次操作的时间正好是我们设置的10s，延迟消息实现成功。\n\n其实还可以设置队列的TTL来控制消息的过期时间，与上雷同，我就不演示了。\n\nDelayExchange插件基于死信队列虽然可以实现延迟消息，但是太麻烦了。因此RabbitMQ社区提供了一个延迟消息插件来实现相同的效果。官方文档说明：Scheduling Messages with RabbitMQ | RabbitMQ - Blog\n安装因为我们是基于Docker安装，所以需要先查看RabbitMQ的插件目录对应的数据卷。\ndocker volume inspect mq-plugins\n\n结果如下：\n[    &#123;        &quot;CreatedAt&quot;: &quot;2024-06-19T09:22:59+08:00&quot;,        &quot;Driver&quot;: &quot;local&quot;,        &quot;Labels&quot;: null,        &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/mq-plugins/_data&quot;,        &quot;Name&quot;: &quot;mq-plugins&quot;,        &quot;Options&quot;: null,        &quot;Scope&quot;: &quot;local&quot;    &#125;]\n\n插件目录被挂载到了/var/lib/docker/volumes/mq-plugins/_data这个目录，我们上传插件到该目录下。\n接下来执行命令，安装插件：\ndocker exec -it mq rabbitmq-plugins enable rabbitmq_delayed_message_exchange\n\n\n\n即可\n\n声明延迟交换机\n注解的方式\n\n多增加一个属性delayed，将其属性值设置为true\n@RabbitListener(bindings = @QueueBinding(        value = @Queue(name = &quot;delay.queue&quot;, durable = &quot;true&quot;),        exchange = @Exchange(name = &quot;delay.direct&quot;, delayed = &quot;true&quot;),        key = &quot;delay&quot;))public void listenDelayMessage(String msg)&#123;    log.info(&quot;接收到delay.queue的延迟消息：&#123;&#125;&quot;, msg);&#125;\n\n\n基于@Bean的方式\n\n@Bean   public DirectExchange delayExchange()&#123;       return ExchangeBuilder               .directExchange(&quot;delay.direct&quot;) // 指定交换机类型和名称               .delayed() // 设置delay的属性为true               .durable(true) // 持久化               .build();   &#125;\n\n创建一个延迟交换机试试\n可以看到延迟转换器的参数和其他的是不同的。\n\n\n发送延迟消息发送消息时，必须通过x-delay属性设定延迟时间：\n@Testvoid testPublisherDelayMessage() &#123;    // 1.创建消息    String message = &quot;hello, delayed message&quot;;    // 2.发送消息，利用消息后置处理器添加消息头    rabbitTemplate.convertAndSend(&quot;delay.direct&quot;, &quot;delay&quot;, message, new MessagePostProcessor() &#123;        @Override        public Message postProcessMessage(Message message) throws AmqpException &#123;            // 添加延迟消息属性            message.getMessageProperties().setDelay(5000);            return message;        &#125;    &#125;);&#125;\n\n\n\n\n\n间隔5s，实现成功。\n注意：延迟消息插件内部会维护一个本地数据库表，同时使用Elang Timers功能实现计时。如果消息的延迟时间设置较长，可能会导致堆积的延迟消息非常多，会带来较大的CPU开销，同时延迟消息的时间会存在误差。因此，不建议设置延迟时间过长的延迟消息。\n\n总结死心队列&#x2F;交换机首先，我们要知道死信是什么，顾名思义就是死掉的消息，它不会再被消费者消费，它会满足以下三点之一：1.被消费者拒绝；2.消息的TTL过期；3.投递的队列满了，最开始进队列的消息就有可能成为死信；\n如果一个队列指定了deed-letter-exhange属性，它指定的这个交换机就成为死信交换机，死信交换机路由的队列就是死信队列。\n死信队列可以处理消费失败的消息，也可以处理过期消息。\n延迟队列延迟队列就是指消息到达mq之后不会立即被消费，它会等到设置的TTL过期之后，消费者才能拿到这个消息进行消费。\n比如订单的超时取消, 订单信息被放到mq中, 30分钟未支付订单就取消. 如果使用延时队列, 那监听mq的消费者从mq中直接拿到的就是，30分钟未支付订单的信息, 然后直接取消订单. 避免轮询数据库查找超时订单.\n实现延迟队列实现延迟队列我有两种策略\n\n发送消息时，给queue1中的消息设置TTL，然后通过交换机发送到queue1,queue1不绑定消费者，它的消息指向queue2，这样当TTL失效后，监听queue2的消费者就是接收的延迟消息；它的优点是RabbitMQ原生，缺点是不够精确，因为MQ会优先处理队头的消息。\n使用DelayExchange插件，通过给设置delay属性的方法声明延迟交换机，被其绑定的队列就是延迟队列，发送出来的带有TTL消息，被消费者消费时，就是延迟消息；它的优点是无需死信中转，精度更高，但是需要下载插件。\n\n","categories":["MQ"],"tags":["MQ"]}]